# Example environment configuration for CURATE
# Copy this file to .env and adjust the values for your setup

# LLM Backend Selection: 'ollama' (default) or 'vllm' (high-performance)
LLM_BACKEND=ollama

# Ollama Configuration (when LLM_BACKEND=ollama)
OLLAMA_HOST=localhost:11434

# vLLM Configuration (when LLM_BACKEND=vllm)
VLLM_HOST=localhost:8001
VLLM_API_KEY=EMPTY
# VLLM_MAX_TOKENS=6000  # Optional: Override max output tokens

# Optional: Override default model
# MODEL_NAME=qwen3:14b

# Fast Extraction Configuration
# FAST_EXTRACTION_MAX_CHUNKS=50  # Limit chunks for speed (0 = no limit)