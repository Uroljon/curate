#!/usr/bin/env python3
"""
Comprehensive test suite for context-awareness fix in operations extraction.

This test file verifies that the context-awareness improvements work as intended:
- Entity registry shows ALL entities (no truncation)
- Context is readable and scannable (not JSON dump) 
- All entity types are emphasized for duplicate checking
- UPDATE is preferred over CREATE for similar entities
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

try:
    # Try direct import first
    from src.api.extraction_helpers import (
        create_extraction_prompt,
        format_context_json,
        format_entity_id_mapping,
        format_entity_registry,
    )
    from src.core.schemas import (
        ConnectionWithConfidence,
        EnhancedActionField,
        EnhancedIndicator,
        EnhancedMeasure,
        EnhancedProject,
        EnrichedReviewJSON,
    )

    # Try importing pytest, but make it optional
    try:
        import pytest
        PYTEST_AVAILABLE = True
    except ImportError:
        PYTEST_AVAILABLE = False
        print("Note: pytest not available, using simple test runner")

        # Create a simple fixture decorator
        def pytest_fixture(func):
            def wrapper():
                return func()
            wrapper.__name__ = func.__name__
            return wrapper

        class pytest:
            fixture = staticmethod(pytest_fixture)

            @staticmethod
            def main(args):
                # Simple test runner
                print("Running tests with simple runner...")
                run_simple_tests()

except ImportError as e:
    print(f"Import error: {e}")
    print("Please run these tests in the virtual environment: source venv/bin/activate")
    sys.exit(1)


# ============================================================================
# FIXTURES - Mock Data for Testing
# ============================================================================


@pytest.fixture
def empty_state() -> EnrichedReviewJSON:
    """Create empty EnrichedReviewJSON state."""
    return EnrichedReviewJSON(action_fields=[], projects=[], measures=[], indicators=[])


@pytest.fixture
def small_state() -> EnrichedReviewJSON:
    """Create state with a few entities of each type."""
    return EnrichedReviewJSON(
        action_fields=[
            EnhancedActionField(
                id="af_1",
                content={"title": "MobilitÃ¤t und Verkehr"},
                connections=[],
            ),
            EnhancedActionField(
                id="af_2",
                content={"title": "Klimaschutz"},
                connections=[],
            ),
        ],
        projects=[
            EnhancedProject(
                id="proj_1",
                content={"title": "Radwegeausbau"},
                connections=[],
            ),
            EnhancedProject(
                id="proj_2",
                content={"title": "E-MobilitÃ¤t FÃ¶rderung"},
                connections=[],
            ),
        ],
        measures=[
            EnhancedMeasure(
                id="msr_1",
                content={"title": "Radweg HauptstraÃŸe"},
                connections=[],
            ),
        ],
        indicators=[
            EnhancedIndicator(
                id="ind_1",
                content={"title": "CO2-Reduktion Verkehr"},
                connections=[],
            ),
        ],
    )


@pytest.fixture
def state_with_duplicates() -> EnrichedReviewJSON:
    """Create state with potential duplicate entity names."""
    return EnrichedReviewJSON(
        action_fields=[
            EnhancedActionField(
                id="af_1",
                content={"title": "MobilitÃ¤t und Verkehr"},
                connections=[],
            ),
            EnhancedActionField(
                id="af_2",
                content={"title": "MobilitÃ¤t & Verkehr"},  # Similar to af_1
                connections=[],
            ),
        ],
        projects=[
            EnhancedProject(
                id="proj_1",
                content={"title": "Radwegeausbau"},
                connections=[],
            ),
            EnhancedProject(
                id="proj_2",
                content={"title": "Ausbau Radwege"},  # Similar to proj_1
                connections=[],
            ),
        ],
        measures=[],
        indicators=[],
    )


@pytest.fixture
def large_state() -> EnrichedReviewJSON:
    """Create state with many entities to test performance and no truncation."""
    action_fields = []
    projects = []
    measures = []
    indicators = []

    # Create 25 entities of each type
    for i in range(25):
        action_fields.append(
            EnhancedActionField(
                id=f"af_{i+1}",
                content={"title": f"Handlungsfeld {i+1}"},
                connections=[],
            )
        )
        projects.append(
            EnhancedProject(
                id=f"proj_{i+1}",
                content={"title": f"Projekt {i+1}"},
                connections=[],
            )
        )
        measures.append(
            EnhancedMeasure(
                id=f"msr_{i+1}",
                content={"title": f"MaÃŸnahme {i+1}"},
                connections=[],
            )
        )
        indicators.append(
            EnhancedIndicator(
                id=f"ind_{i+1}",
                content={"title": f"Indikator {i+1}"},
                connections=[],
            )
        )

    return EnrichedReviewJSON(
        action_fields=action_fields,
        projects=projects,
        measures=measures,
        indicators=indicators,
    )


@pytest.fixture
def state_with_special_chars() -> EnrichedReviewJSON:
    """Create state with special characters and unicode."""
    return EnrichedReviewJSON(
        action_fields=[
            EnhancedActionField(
                id="af_1",
                content={"title": "MobilitÃ¤t & Verkehr (Hauptthema)"},
                connections=[],
            ),
            EnhancedActionField(
                id="af_2",
                content={"title": "Klimaschutz: COâ‚‚-Reduktion"},
                connections=[],
            ),
        ],
        projects=[
            EnhancedProject(
                id="proj_1",
                content={"title": "E-MobilitÃ¤t \"FÃ¶rderung\" 2024-2030"},
                connections=[],
            ),
        ],
        measures=[
            EnhancedMeasure(
                id="msr_1",
                content={"title": "StraÃŸenbau fÃ¼r RÃ¤der & FuÃŸgÃ¤nger"},
                connections=[],
            ),
        ],
        indicators=[
            EnhancedIndicator(
                id="ind_1",
                content={"title": "50% weniger COâ‚‚ bis 2030"},
                connections=[],
            ),
        ],
    )


# ============================================================================
# SIMPLE TEST RUNNER (when pytest not available)
# ============================================================================


def run_simple_tests():
    """Run tests with simple runner when pytest is not available."""
    print("ðŸ§ª Running Context-Awareness Tests")
    print("=" * 80)

    # Global test counters
    global tests_passed, tests_total
    tests_passed = 0
    tests_total = 0

    # Helper function to run individual tests
    def run_test(test_name: str, test_func):
        global tests_passed, tests_total
        tests_total += 1
        try:
            test_func()
            print(f"âœ… {test_name}")
            tests_passed += 1
        except Exception as e:
            print(f"âŒ {test_name}: {e}")

    # Create fixtures manually
    empty_state = EnrichedReviewJSON(action_fields=[], projects=[], measures=[], indicators=[])

    small_state = EnrichedReviewJSON(
        action_fields=[
            EnhancedActionField(id="af_1", content={"title": "MobilitÃ¤t und Verkehr"}, connections=[]),
            EnhancedActionField(id="af_2", content={"title": "Klimaschutz"}, connections=[]),
        ],
        projects=[
            EnhancedProject(id="proj_1", content={"title": "Radwegeausbau"}, connections=[]),
            EnhancedProject(id="proj_2", content={"title": "E-MobilitÃ¤t FÃ¶rderung"}, connections=[]),
        ],
        measures=[EnhancedMeasure(id="msr_1", content={"title": "Radweg HauptstraÃŸe"}, connections=[])],
        indicators=[EnhancedIndicator(id="ind_1", content={"title": "CO2-Reduktion Verkehr"}, connections=[])]
    )

    # Test 1: Entity registry shows all entities
    def test_entity_registry_all_entities():
        registry = format_entity_registry(small_state)
        assert "ACTION FIELDS (2 total):" in registry
        assert "PROJECTS (2 total):" in registry
        assert "MobilitÃ¤t und Verkehr" in registry
        assert "Radwegeausbau" in registry
        assert "[None yet]" not in registry  # Should have entities

    run_test("Entity registry shows all entities", test_entity_registry_all_entities)

    # Test 2: ID mapping format is correct
    def test_id_mapping_format():
        id_mapping = format_entity_id_mapping(small_state)
        assert "af_1 â†’ MobilitÃ¤t und Verkehr" in id_mapping
        assert "proj_1 â†’ Radwegeausbau" in id_mapping
        assert "msr_1 â†’ Radweg HauptstraÃŸe" in id_mapping
        assert "ind_1 â†’ CO2-Reduktion Verkehr" in id_mapping

    run_test("ID mapping format is correct", test_id_mapping_format)

    # Test 3: Context avoids JSON dump
    def test_context_avoids_json_dump():
        context = format_context_json(small_state)
        # Should NOT contain JSON dump format
        assert "AKTUELLER EXTRAKTIONSSTAND" not in context
        assert '{"action_fields":' not in context
        # Should contain registry format
        assert "ENTITY REGISTRY" in context
        assert "af_1 â†’ MobilitÃ¤t und Verkehr" in context

    run_test("Context avoids JSON dump", test_context_avoids_json_dump)

    # Test 4: Context includes duplicate examples
    def test_duplicate_examples():
        context = format_context_json(small_state)
        assert "MobilitÃ¤t und Verkehr" in context
        assert "MobilitÃ¤t & Verkehr" in context
        assert "Radwegeausbau" in context
        assert "Ausbau Radwege" in context
        assert "CO2-Reduktion" in context
        assert "COâ‚‚-Reduktion" in context

    run_test("Context includes duplicate examples", test_duplicate_examples)

    # Test 5: Prompt uses registry format
    def test_prompt_uses_registry():
        prompt = create_extraction_prompt("operations", "Test text", small_state, [1])
        assert "ENTITY REGISTRY" in prompt
        assert "1. Entity bereits im ENTITY REGISTRY? â†’ UPDATE verwenden" in prompt
        # Should NOT contain old format
        assert "AKTUELLER EXTRAKTIONSSTAND" not in prompt

    run_test("Prompt uses registry format", test_prompt_uses_registry)

    # Test 6: Empty state handling
    def test_empty_state_handling():
        context = format_context_json(None)
        assert context == "ERSTER CHUNK: Noch keine Entities extrahiert. Beginnen Sie mit CREATE-Operationen."

        registry = format_entity_registry(empty_state)
        assert "[None yet]" in registry
        assert "ACTION FIELDS (0 total):" in registry

        id_mapping = format_entity_id_mapping(empty_state)
        assert id_mapping == "No entities yet - use CREATE operations"

    run_test("Empty state handling", test_empty_state_handling)

    print("=" * 80)
    print(f"RESULTS: {tests_passed}/{tests_total} tests passed")
    if tests_passed == tests_total:
        print("ðŸŽ‰ ALL TESTS PASSED! Context-awareness fix is working correctly.")
        print("Key improvements verified:")
        print("  âœ“ Entity registry shows ALL entities (no truncation)")
        print("  âœ“ Context is readable and scannable (not JSON dump)")
        print("  âœ“ All entity types are emphasized for duplicate checking")
        print("  âœ“ UPDATE is preferred over CREATE via decision logic")
        print("  âœ“ Duplicate examples help LLM identify similar entities")
    else:
        print("âŒ Some tests failed. Please check the implementation.")
    print("=" * 80)


# ============================================================================
# MAIN EXECUTION
# ============================================================================

if __name__ == "__main__":
    if len(sys.argv) > 1:
        # Use pytest if available and requested
        if PYTEST_AVAILABLE:
            pytest.main(sys.argv[1:])
        else:
            print("pytest not available, falling back to simple runner")
            run_simple_tests()
    else:
        # Default to simple runner
        run_simple_tests()
